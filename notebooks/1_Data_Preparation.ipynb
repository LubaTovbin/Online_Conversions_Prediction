{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Chalice assessment: Data Preparation\"\n",
    "author: Liubov (Luba) Tovbin\n",
    "date: \"2024/11/19\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "In this notebook, we create a clean, balanced training dataset and a testing dataset that emulates real-world data. In addition, we perform feature engineering to determine the optimal feature set and encode both datasets to get the model's input ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_theme(context='notebook', style='whitegrid')\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw data\n",
    "conversion_data = pd.read_csv('../data/0_raw/Conversion_data.csv')\n",
    "nonconversion_data = pd.read_csv('../data/0_raw/nonconversion_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Let's create a clean, balanced training dataset by removing null values and combining the same number of conversion and non-conversion data points. The balanced dataset prevents the model from being biased towards the majority class (non-conversions).\n",
    "\n",
    "We'll remove the null values for the testing dataset but keep class imbalance to emulate the real-world data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean column names by removing non-alphanumeric characters\n",
    "conversion_data.columns = conversion_data.columns.str.replace(r'^[^a-zA-Z0-9]+|[^a-zA-Z0-9]+$', '', regex=True)\n",
    "nonconversion_data.columns = nonconversion_data.columns.str.replace(r'^[^a-zA-Z0-9]+|[^a-zA-Z0-9]+$', '', regex=True)\n",
    "\n",
    "# Check if ther columns' name are the same now\n",
    "(conversion_data.columns == nonconversion_data.columns).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with null values\n",
    "conversion_data = conversion_data.dropna().reset_index(drop=True)\n",
    "nonconversion_data = nonconversion_data.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class column in the conversion and non-conversion datasets\n",
    "# 1 means conversion \n",
    "# 0 means non conversion\n",
    "conversion_data['CLASS'] = 1\n",
    "nonconversion_data['CLASS'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the conversion data and perform a 80-20% train-test split \n",
    "conversion_data = conversion_data.sample(frac=1, random_state=11).reset_index(drop=True)\n",
    "n = int(0.8 * len(conversion_data))\n",
    "conversion_train = conversion_data[:n]\n",
    "conversion_test = conversion_data[n:]\n",
    "\n",
    "# Shuffle the non-conversion data and select n rows for training\n",
    "nonconversion_data = nonconversion_data.sample(frac=1, random_state=11).reset_index(drop=True)\n",
    "nonconversion_train = nonconversion_data[:n]\n",
    "# For non-conversion test set, select three times more rows than in the conversion_test \n",
    "# to preserve the initial 3:1 ratio of non-conversion vs. conversion data.\n",
    "m = len(conversion_test)\n",
    "nonconversion_test = nonconversion_data[n: n + 3*m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the conversion data non-conversion for train and test sets\n",
    "train_data = pd.concat([conversion_train, nonconversion_train]).reset_index(drop=True)\n",
    "test_data  = pd.concat([conversion_test, nonconversion_test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SITE</th>\n",
       "      <th>AD_FORMAT</th>\n",
       "      <th>BROWSER_NAME</th>\n",
       "      <th>SUPPLY_VENDOR</th>\n",
       "      <th>METRO</th>\n",
       "      <th>OS_FAMILY_NAME</th>\n",
       "      <th>USER_HOUR_OF_WEEK</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLASS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78069</td>\n",
       "      <td>78069</td>\n",
       "      <td>78069</td>\n",
       "      <td>78069</td>\n",
       "      <td>78069</td>\n",
       "      <td>78069</td>\n",
       "      <td>78069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78069</td>\n",
       "      <td>78069</td>\n",
       "      <td>78069</td>\n",
       "      <td>78069</td>\n",
       "      <td>78069</td>\n",
       "      <td>78069</td>\n",
       "      <td>78069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SITE  AD_FORMAT  BROWSER_NAME  SUPPLY_VENDOR  METRO  OS_FAMILY_NAME  \\\n",
       "CLASS                                                                         \n",
       "0      78069      78069         78069          78069  78069           78069   \n",
       "1      78069      78069         78069          78069  78069           78069   \n",
       "\n",
       "       USER_HOUR_OF_WEEK  \n",
       "CLASS                     \n",
       "0                  78069  \n",
       "1                  78069  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the data is balnced\n",
    "train_data.groupby('CLASS').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting training set is slightly imbalanced with more data points of class 1, the conversions. \n",
    "Since the XGBoost and Random Forest algorithms are robust to slight class imbalance, we won't rebalance the training set to avoid losing more data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clean data sets\n",
    "train_data.to_csv('../data/1_processed/train_data.csv', index=False)\n",
    "test_data.to_csv('../data/1_processed/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering (Light)\n",
    "\n",
    "At first, we try only minimal feature manipulation to establish a baseline performance. Later, we will use more advanced feature selection techniques to see whether or not we can improve the model's performance.\n",
    "\n",
    "We notice that the SITE column is problematic. Its high cardinality can lead to overfitting and lower model interpretability. We will drop the SITE column from the training set.\n",
    "\n",
    "Lastly, we encode the categorical features. Since we are going to use tree-based methods for classification, we can use an OrdinalEncoder. Tree-based models decide splits based on thresholds rather than interpreting the encoded values as distances or magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the SITE column from both, the train and the test sets\n",
    "train_data = train_data.drop(columns=['SITE'])\n",
    "test_data = test_data.drop(columns=['SITE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AD_FORMAT</th>\n",
       "      <th>BROWSER_NAME</th>\n",
       "      <th>SUPPLY_VENDOR</th>\n",
       "      <th>METRO</th>\n",
       "      <th>OS_FAMILY_NAME</th>\n",
       "      <th>USER_HOUR_OF_WEEK</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300x250</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Media.Net</td>\n",
       "      <td>770.0</td>\n",
       "      <td>Windows</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>728x90</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Xandr – Monetize SSP (AppNexus)</td>\n",
       "      <td>519.0</td>\n",
       "      <td>OS X</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300x250</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Index Exchange</td>\n",
       "      <td>505.0</td>\n",
       "      <td>Windows</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AD_FORMAT BROWSER_NAME                    SUPPLY_VENDOR  METRO  \\\n",
       "0   300x250       Chrome                        Media.Net  770.0   \n",
       "1    728x90       Chrome  Xandr – Monetize SSP (AppNexus)  519.0   \n",
       "2   300x250       Chrome                   Index Exchange  505.0   \n",
       "\n",
       "  OS_FAMILY_NAME  USER_HOUR_OF_WEEK  CLASS  \n",
       "0        Windows               35.0      1  \n",
       "1           OS X               13.0      1  \n",
       "2        Windows               45.0      1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to encode\n",
    "columns_to_encode = train_data.select_dtypes('object').columns\n",
    "\n",
    "# Initialize the OrdinalEncoder with handling for unknown categories\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# Fit the encoder on the training data\n",
    "ordinal_encoder.fit(train_data[columns_to_encode])\n",
    "\n",
    "# Transform both training and test data\n",
    "train_data_encoded = train_data.copy()\n",
    "test_data_encoded = test_data.copy()\n",
    "\n",
    "train_data_encoded[columns_to_encode] = ordinal_encoder.transform(train_data[columns_to_encode])\n",
    "test_data_encoded[columns_to_encode] = ordinal_encoder.transform(test_data[columns_to_encode])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AD_FORMAT</th>\n",
       "      <th>BROWSER_NAME</th>\n",
       "      <th>SUPPLY_VENDOR</th>\n",
       "      <th>METRO</th>\n",
       "      <th>OS_FAMILY_NAME</th>\n",
       "      <th>USER_HOUR_OF_WEEK</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AD_FORMAT  BROWSER_NAME  SUPPLY_VENDOR  METRO  OS_FAMILY_NAME  \\\n",
       "0        3.0           0.0           45.0  528.0             4.0   \n",
       "1        1.0           0.0           26.0  501.0             4.0   \n",
       "2        7.0           0.0           78.0  505.0             2.0   \n",
       "\n",
       "   USER_HOUR_OF_WEEK  CLASS  \n",
       "0              131.0      1  \n",
       "1               59.0      1  \n",
       "2               40.0      1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_encoded[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the encoded data sets\n",
    "train_data_encoded.to_csv('../data/1_processed/train_data_encoded.csv', index=False)\n",
    "test_data_encoded.to_csv('../data/1_processed/test_data_encoded.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
