{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Chalice assessment: Model Evaliation\"\n",
    "author: Liubov (Luba) Tovbin\n",
    "date: \"2024/11/19\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from helper_functions.utils import evaluate_fairness_by_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_xgb = pd.read_csv('../data/3_evaluation/XGBClassifier_results.csv')\n",
    "results_xgb_engineered = pd.read_csv('../data/3_evaluation/XGBClassifier_engineered_results.csv')\n",
    "results_xgb_tunned = pd.read_csv('../data/3_evaluation/XGBClassifier_tunned_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate  accuracy, global precision, recall, and F1-score\n",
    "results = {\n",
    "    'Model': [\"XGB\", \"XGB_engineered\", \"XGB_tunned\"],\n",
    "    'Accuracy':  [],\n",
    "    'Precision': [],\n",
    "    'Recall':    [],\n",
    "    'F1-Score':  [],\n",
    "    'ROC-AUC':   [],\n",
    "}\n",
    "\n",
    "for df in [results_xgb, results_xgb_engineered, results_xgb_tunned]:\n",
    "    results['Accuracy'].append(accuracy_score(df['CLASS'], df['CLASS_pred']))\n",
    "    results['Precision'].append(precision_score(df['CLASS'], df['CLASS_pred']))\n",
    "    results['Recall'].append(recall_score(df['CLASS'], df['CLASS_pred']))\n",
    "    results['F1-Score'].append(f1_score(df['CLASS'], df['CLASS_pred']))\n",
    "    results['ROC-AUC'].append(roc_auc_score(df['CLASS'], df['CLASS_pred']))\n",
    "\n",
    "# Create a DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.820717</td>\n",
       "      <td>0.606006</td>\n",
       "      <td>0.808536</td>\n",
       "      <td>0.692772</td>\n",
       "      <td>0.816656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGB_engineered</td>\n",
       "      <td>0.760977</td>\n",
       "      <td>0.514855</td>\n",
       "      <td>0.760887</td>\n",
       "      <td>0.614147</td>\n",
       "      <td>0.760947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB_tunned</td>\n",
       "      <td>0.834499</td>\n",
       "      <td>0.631023</td>\n",
       "      <td>0.813915</td>\n",
       "      <td>0.710894</td>\n",
       "      <td>0.827638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  Accuracy  Precision    Recall  F1-Score   ROC-AUC\n",
       "0             XGB  0.820717   0.606006  0.808536  0.692772  0.816656\n",
       "1  XGB_engineered  0.760977   0.514855  0.760887  0.614147  0.760947\n",
       "2      XGB_tunned  0.834499   0.631023  0.813915  0.710894  0.827638"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resulsts Discussion\n",
    "\n",
    "The tuned XGBoost model with all initial features is the best-performing model, improving across all metrics. An attempt to modify a feature set resulted in a much lower performance across all metrics, even compared to the baseline, untuned XGBoost.\n",
    "\n",
    "The XGBoost tuned correctly classified 83% of the instances. It is better at avoiding false positives, with 63% precision. Avoiding false positives is critical if we want to optimize the ad spend. The model best identifies actual conversions, with 81% recall, which is essential if missing a conversion is costly. \n",
    "\n",
    "The 71% F1 score confirms that the tuned model is better at balancing precision and recall. The 83% ROC-AUC shows the model's ability to distinguish between positive and negative classes across all thresholds, and it is also the highest for the tuned XGBoost model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Detection\n",
    "\n",
    "Let's check for biases in the model. We'll group the data by a potentially problematic feature, such as OS_FAMILY_NAME, and measure each group's **accuracy** and **selection rate**. \n",
    "\n",
    "The accuracy will give us a percentage of correct predictions within each group and the selection rate - a proportion of points in each group we predicted as conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data before encoding\n",
    "test_data = pd.read_csv('../data/1_processed/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SITE</th>\n",
       "      <th>AD_FORMAT</th>\n",
       "      <th>BROWSER_NAME</th>\n",
       "      <th>SUPPLY_VENDOR</th>\n",
       "      <th>METRO</th>\n",
       "      <th>OS_FAMILY_NAME</th>\n",
       "      <th>USER_HOUR_OF_WEEK</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mail.yahoo.com</td>\n",
       "      <td>300x50</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>google</td>\n",
       "      <td>528.0</td>\n",
       "      <td>Windows</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ebay.com</td>\n",
       "      <td>160x600</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Xandr – Monetize SSP (AppNexus)</td>\n",
       "      <td>501.0</td>\n",
       "      <td>Windows</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logicaldollar.com</td>\n",
       "      <td>640x360</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>yieldmo</td>\n",
       "      <td>505.0</td>\n",
       "      <td>OS X</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SITE AD_FORMAT BROWSER_NAME                    SUPPLY_VENDOR  \\\n",
       "0     mail.yahoo.com    300x50       Chrome                           google   \n",
       "1           ebay.com   160x600       Chrome  Xandr – Monetize SSP (AppNexus)   \n",
       "2  logicaldollar.com   640x360       Chrome                          yieldmo   \n",
       "\n",
       "   METRO OS_FAMILY_NAME  USER_HOUR_OF_WEEK  CLASS  \n",
       "0  528.0        Windows              131.0      1  \n",
       "1  501.0        Windows               59.0      1  \n",
       "2  505.0           OS X               40.0      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that CLASS labels match\n",
    "(results_xgb_tunned['CLASS'] == test_data['CLASS']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.drop(columns=['CLASS'])\n",
    "y_test = test_data['CLASS']\n",
    "y_pred = results_xgb_tunned['CLASS_pred'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group-wise Metrics (Sorted by Accuracy):\n",
      "                Accuracy  Selection Rate\n",
      "OS_FAMILY_NAME                          \n",
      "Other           0.894737        0.230263\n",
      "iOS             0.883759        0.199480\n",
      "Android         0.845995        0.280338\n",
      "Linux           0.827757        0.293061\n",
      "Windows         0.818847        0.378442\n",
      "OS X            0.803459        0.373690\n",
      "\n",
      "Overall Metrics:\n",
      "Accuracy          0.834499\n",
      "Selection Rate    0.322459\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sorted_metrics, overall_metrics = evaluate_fairness_by_group(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    sensitive_feature_column=X_test['OS_FAMILY_NAME'],\n",
    "    metric=\"Accuracy\"\n",
    ")\n",
    "\n",
    "print(\"Group-wise Metrics (Sorted by Accuracy):\")\n",
    "print(sorted_metrics)\n",
    "\n",
    "print(\"\\nOverall Metrics:\")\n",
    "print(overall_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group-wise Metrics (Sorted by Accuracy):\n",
      "                      Accuracy  Selection Rate\n",
      "BROWSER_NAME                                  \n",
      "Internet Explorer 7   1.000000        0.000000\n",
      "Internet Explorer 11  0.991150        0.000000\n",
      "WebView               0.972979        0.036134\n",
      "Other                 0.922414        0.172414\n",
      "Edge                  0.880898        0.211200\n",
      "Firefox               0.865714        0.200000\n",
      "Chrome                0.802948        0.391944\n",
      "Safari                0.798089        0.351274\n",
      "Opera                 0.783019        0.339623\n",
      "\n",
      "Overall Metrics:\n",
      "Accuracy          0.834499\n",
      "Selection Rate    0.322459\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sorted_metrics, overall_metrics = evaluate_fairness_by_group(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    sensitive_feature_column=X_test['BROWSER_NAME'],\n",
    "    metric=\"Accuracy\"\n",
    ")\n",
    "\n",
    "print(\"Group-wise Metrics (Sorted by Accuracy):\")\n",
    "print(sorted_metrics)\n",
    "\n",
    "print(\"\\nOverall Metrics:\")\n",
    "print(overall_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Analysis\n",
    "\n",
    "The Windows users group has the highest selection rate and second to lowest accuracy. That indicates that our model is biased towards Windows users, predicting conversion for them more often than it should.\n",
    "\n",
    "The Chrome users group has the highest selection rate with 3rd to lowest accuracy. However, we know that Chrome users dominate our dataset along with Windows users (obviously, the two largely intersecting users' sets). More data points mean more room for errors. (See output_images/OS_FAMILY_NAME_categorical.png and output_images/BROWSER_NAME_categorical.png)\n",
    "\n",
    "The accuracy doesn't change dramatically across the OS_FAMILY_NAME or BROWSER_NAME groups, meaning the model is relatively fair.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
